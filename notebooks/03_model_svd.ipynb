{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad33051",
   "metadata": {},
   "source": [
    "# 03) Matrix Factorization (SVD-style) — MovieLens 100K\n",
    "\n",
    "เป้าหมาย: เทรนโมเดลแบบ FunkSVD (มี bias) เพื่อพยากรณ์เรตติ้งและวัดผลด้วย RMSE + Precision@K/Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "339ea0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: G:\\BU\\PhiphatD_Web_Portfolio\\Recommendation-System-MovieLens-100K-\\data\\final_data.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "PROJ = Path.cwd()\n",
    "DATA = PROJ / \"data\"\n",
    "RESULTS = PROJ / \"results\"\n",
    "RESULTS.mkdir(exist_ok=True)\n",
    "\n",
    "def find_final_csv():\n",
    "    cands = [\n",
    "        DATA / \"final_data.csv\",\n",
    "        PROJ.parent / \"data\" / \"final_data.csv\",\n",
    "        PROJ.parent.parent / \"data\" / \"final_data.csv\",\n",
    "    ]\n",
    "    for p in cands:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"ไม่พบ data/final_data.csv — กลับไปรัน 01_data_cleaning.ipynb เพื่อ export ก่อน\")\n",
    "\n",
    "CSV_PATH = find_final_csv()\n",
    "print(\"Using:\", CSV_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f18946",
   "metadata": {},
   "source": [
    "# 3.1) Load dataset\n",
    "\n",
    "โหลดข้อมูลและตรวจคอลัมน์สำคัญ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1fd0a1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "user_idx",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "item_idx",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "rating",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "movie_title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "0a174b06-cb45-4fbb-a304-22ca1835b21e",
       "rows": [
        [
         "0",
         "195",
         "241",
         "3.0",
         "Kolya (1996)"
        ],
        [
         "1",
         "185",
         "301",
         "3.0",
         "L.A. Confidential (1997)"
        ],
        [
         "2",
         "21",
         "376",
         "1.0",
         "Heavyweights (1994)"
        ],
        [
         "3",
         "243",
         "50",
         "2.0",
         "Legends of the Fall (1994)"
        ],
        [
         "4",
         "165",
         "345",
         "1.0",
         "Jackie Brown (1997)"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>item_idx</th>\n",
       "      <th>rating</th>\n",
       "      <th>movie_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3.0</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_idx  item_idx  rating                 movie_title\n",
       "0       195       241     3.0                Kolya (1996)\n",
       "1       185       301     3.0    L.A. Confidential (1997)\n",
       "2        21       376     1.0         Heavyweights (1994)\n",
       "3       243        50     2.0  Legends of the Fall (1994)\n",
       "4       165       345     1.0         Jackie Brown (1997)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# ถ้ายังไม่มี user_idx / item_idx ให้เข้ารหัสตอนนี้\n",
    "if not {\"user_idx\",\"item_idx\"}.issubset(df.columns):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    uenc, ienc = LabelEncoder(), LabelEncoder()\n",
    "    df[\"user_idx\"] = uenc.fit_transform(df[\"user_id\"])\n",
    "    df[\"item_idx\"] = ienc.fit_transform(df[\"item_id\"])\n",
    "\n",
    "# เก็บเฉพาะคอลัมน์ที่จำเป็นต่อโมเดล + ชื่อหนังเพื่อโชว์ผล\n",
    "keep_cols = [\"user_idx\",\"item_idx\",\"rating\"]\n",
    "if \"movie_title\" in df.columns:\n",
    "    keep_cols += [\"movie_title\"]\n",
    "df = df[keep_cols].copy()\n",
    "\n",
    "# ชนิดข้อมูลที่เหมาะกับโมเดล (เร็ว/ประหยัดแรม)\n",
    "df[\"user_idx\"] = df[\"user_idx\"].astype(np.int32)\n",
    "df[\"item_idx\"] = df[\"item_idx\"].astype(np.int32)\n",
    "df[\"rating\"]   = df[\"rating\"].astype(np.float32)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6cbd0f",
   "metadata": {},
   "source": [
    "# 3.2) Quick sanity check\n",
    "\n",
    "จำนวนผู้ใช้/หนัง/ความหนาแน่น rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92676a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users=943, Items=1,682, Ratings=99,991, Density=6.3041%\n"
     ]
    }
   ],
   "source": [
    "n_users = int(df[\"user_idx\"].max()) + 1\n",
    "n_items = int(df[\"item_idx\"].max()) + 1\n",
    "density = len(df) / (n_users * n_items) * 100\n",
    "\n",
    "print(f\"Users={n_users:,}, Items={n_items:,}, Ratings={len(df):,}, Density={density:.4f}%\")\n",
    "assert {\"user_idx\",\"item_idx\",\"rating\"}.issubset(df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72439bf5",
   "metadata": {},
   "source": [
    "# 3.3) Train/Test split แบบ per-user\n",
    "\n",
    "คงสถานการณ์จริง: แบ่ง 80/20 ภายในแต่ละผู้ใช้ เพื่อลด data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "455328cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (79610, 4)  test: (20381, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "splits = [train_test_split(g, test_size=0.2, random_state=42) for _, g in df.groupby(\"user_idx\")]\n",
    "train_df = pd.concat([p[0] for p in splits], ignore_index=True)\n",
    "test_df  = pd.concat([p[1] for p in splits], ignore_index=True)\n",
    "\n",
    "print(\"train:\", train_df.shape, \" test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f066c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#เตรียมอาร์เรย์สำหรับโมเดล ให้ NumPy จัดการตรง ๆ\n",
    "u_tr = train_df[\"user_idx\"].to_numpy(np.int32)\n",
    "i_tr = train_df[\"item_idx\"].to_numpy(np.int32)\n",
    "r_tr = train_df[\"rating\"].to_numpy(np.float32)\n",
    "\n",
    "u_te = test_df[\"user_idx\"].to_numpy(np.int32)\n",
    "i_te = test_df[\"item_idx\"].to_numpy(np.int32)\n",
    "r_te = test_df[\"rating\"].to_numpy(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f2dc0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def funk_svd(u_tr, i_tr, r_tr, n_users, n_items,\n",
    "             n_factors=50, n_epochs=10, lr=0.005, reg=0.02, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    P  = 0.1 * rng.standard_normal((n_users, n_factors))  # user factors\n",
    "    Q  = 0.1 * rng.standard_normal((n_items, n_factors))  # item factors\n",
    "    bu = np.zeros(n_users, dtype=np.float32)              # user bias\n",
    "    bi = np.zeros(n_items, dtype=np.float32)              # item bias\n",
    "    mu = float(r_tr.mean())                               # global mean\n",
    "\n",
    "    idx = np.arange(len(r_tr))\n",
    "    for epoch in range(n_epochs):\n",
    "        rng.shuffle(idx)\n",
    "        for t in idx:\n",
    "            u, i, r = int(u_tr[t]), int(i_tr[t]), float(r_tr[t])\n",
    "            pred = mu + bu[u] + bi[i] + P[u] @ Q[i]\n",
    "            err  = r - pred\n",
    "\n",
    "            # อัปเดต bias\n",
    "            bu[u] += lr * (err - reg*bu[u])\n",
    "            bi[i] += lr * (err - reg*bi[i])\n",
    "\n",
    "            # อัปเดต latent factors\n",
    "            Pu, Qi = P[u].copy(), Q[i].copy()\n",
    "            P[u] += lr * (err*Qi - reg*Pu)\n",
    "            Q[i] += lr * (err*Pu - reg*Qi)\n",
    "    return {\"P\":P, \"Q\":Q, \"bu\":bu, \"bi\":bi, \"mu\":mu}\n",
    "\n",
    "def predict(params, u, i):\n",
    "    P,Q,bu,bi,mu = params[\"P\"],params[\"Q\"],params[\"bu\"],params[\"bi\"],params[\"mu\"]\n",
    "    s = mu + bu[u] + bi[i] + P[u] @ Q[i]\n",
    "    return float(np.clip(s, 1.0, 5.0))\n",
    "\n",
    "def rmse(params, u, i, r):\n",
    "    pred = np.array([predict(params, int(uu), int(ii)) for uu,ii in zip(u,i)], dtype=np.float32)\n",
    "    return float(np.sqrt(np.mean((r - pred)**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e9bfd0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE(test) = 0.9435\n"
     ]
    }
   ],
   "source": [
    "params = funk_svd(\n",
    "    u_tr, i_tr, r_tr,\n",
    "    n_users=n_users, n_items=n_items,\n",
    "    n_factors=50, n_epochs=10, lr=0.005, reg=0.02, seed=42\n",
    ")\n",
    "rmse_test = rmse(params, u_te, i_te, r_te)\n",
    "print(f\"RMSE(test) = {rmse_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "453fafcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@10=0.0635  Recall@10=0.0435\n"
     ]
    }
   ],
   "source": [
    "def topk_for_user(params, u, seen_items=None, k=10):\n",
    "    # คะแนนทุก item สำหรับ user u\n",
    "    scores = params[\"mu\"] + params[\"bu\"][u] + params[\"bi\"] + params[\"P\"][u] @ params[\"Q\"].T\n",
    "    if seen_items:\n",
    "        scores[list(seen_items)] = -np.inf  # ไม่แนะนำสิ่งที่เคยให้คะแนนแล้ว\n",
    "    valid = np.isfinite(scores)\n",
    "    k_eff = min(k, int(valid.sum()))\n",
    "    idx = np.argpartition(-scores, k_eff-1)[:k_eff]\n",
    "    return idx[np.argsort(-scores[idx])]\n",
    "\n",
    "def precision_recall_at_k(params, train_df, test_df, k=10, threshold=4.0):\n",
    "    seen = train_df.groupby(\"user_idx\")[\"item_idx\"].apply(set).to_dict()\n",
    "    precisions, recalls = [], []\n",
    "    for u, g in test_df.groupby(\"user_idx\"):\n",
    "        u = int(u)\n",
    "        topk = set(topk_for_user(params, u, seen.get(u, set()), k))\n",
    "        rel  = set(g.loc[g[\"rating\"]>=threshold, \"item_idx\"].astype(int))\n",
    "        if len(topk) == 0:\n",
    "            continue\n",
    "        tp = len(topk & rel)\n",
    "        precisions.append(tp/len(topk))\n",
    "        recalls.append(tp/max(len(rel),1))\n",
    "    return float(np.mean(precisions)), float(np.mean(recalls))\n",
    "\n",
    "P10, R10 = precision_recall_at_k(params, train_df, test_df, k=10, threshold=4.0)\n",
    "print(f\"Precision@10={P10:.4f}  Recall@10={R10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6f59aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 649 → Top-10\n",
      " 1. Schindler's List (1993)\n",
      " 2. Wrong Trousers, The (1993)\n",
      " 3. Close Shave, A (1995)\n",
      " 4. Shawshank Redemption, The (1994)\n",
      " 5. Wallace & Gromit: The Best of Aardman Animation (1996)\n",
      " 6. Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)\n",
      " 7. Usual Suspects, The (1995)\n",
      " 8. Raging Bull (1980)\n",
      " 9. 12 Angry Men (1957)\n",
      "10. Star Wars (1977)\n"
     ]
    }
   ],
   "source": [
    "# mapping item_idx -> movie_title (ถ้ามี)\n",
    "title_map = {}\n",
    "if \"movie_title\" in df.columns:\n",
    "    title_map = df.drop_duplicates(\"item_idx\").set_index(\"item_idx\")[\"movie_title\"].to_dict()\n",
    "\n",
    "sample_user = int(train_df.sample(1, random_state=0)[\"user_idx\"].iloc[0])\n",
    "seen_items = set(train_df.loc[train_df[\"user_idx\"]==sample_user, \"item_idx\"].astype(int))\n",
    "top_ids = topk_for_user(params, sample_user, seen_items, k=10)\n",
    "\n",
    "print(f\"User {sample_user} → Top-10\")\n",
    "for rnk, iid in enumerate(top_ids, 1):\n",
    "    print(f\"{rnk:2d}.\", title_map.get(int(iid), f\"item_{int(iid)}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0cde41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: svd_params.npz svd_eval.json\n"
     ]
    }
   ],
   "source": [
    "np.savez_compressed(\n",
    "    RESULTS / \"svd_params.npz\",\n",
    "    P=params[\"P\"], Q=params[\"Q\"], bu=params[\"bu\"], bi=params[\"bi\"], mu=np.array([params[\"mu\"]])\n",
    ")\n",
    "with open(RESULTS / \"svd_eval.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"rmse_test\": rmse_test, \"precision@10\": P10, \"recall@10\": R10}, f, indent=2)\n",
    "print(\"Saved:\", (RESULTS / \"svd_params.npz\").name, (RESULTS / \"svd_eval.json\").name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c8e5bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_factors': 150, 'n_epochs': 40, 'lr': 0.004, 'reg': 0.03} -> RMSE 0.9333 | P@10 0.0768 R@10 0.0567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_factors': 150, 'n_epochs': 40, 'lr': 0.004, 'reg': 0.03},\n",
       " 0.9332975149154663,\n",
       " 0.0767762460233298,\n",
       " 0.0566557415775462)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = [\n",
    "    dict(n_factors=150, n_epochs=40, lr=0.004, reg=0.03),\n",
    "]\n",
    "res = []\n",
    "for hp in grid:\n",
    "    p = funk_svd(u_tr, i_tr, r_tr, n_users, n_items, seed=7, **hp)\n",
    "    rm = rmse(p, u_te, i_te, r_te)\n",
    "    pr, rc = precision_recall_at_k(p, train_df, test_df, k=10, threshold=4.0)\n",
    "    res.append((hp, rm, pr, rc))\n",
    "    print(hp, \"-> RMSE\", f\"{rm:.4f}\", \"| P@10\", f\"{pr:.4f}\", \"R@10\", f\"{rc:.4f}\")\n",
    "\n",
    "# เลือกชุดที่ชอบตามเมตริกที่ต้องการ (เช่น RMSE ต่ำสุด)\n",
    "best = min(res, key=lambda x: x[1])\n",
    "best\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
